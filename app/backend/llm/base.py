from abc import ABC, abstractmethod
import yaml
from pathlib import Path

class BaseLLM(ABC):
    """Abstract base class for all LLM connectors."""

    def __init__(self, model: str, api_key: str | None = None):
        """
        Initializes the LLM connector.

        Args:
            model: The specific model to use (e.g., "gemini-1.5-flash").
            api_key: The API key for the service, if required.
        """
        self.api_key = api_key
        self.model = model

    @abstractmethod
    def generate_response(self, system_prompt: str, user_prompt: str) -> str:
        """
        Generates a response from the language model.

        Args:
            system_prompt: The system prompt that defines the AI's persona and instructions.
            user_prompt: The user's input to which the AI should respond.

        Returns:
            The text response generated by the model.
        """
        pass

    @staticmethod
    def load_config() -> dict:
        """Loads the LLM configuration from the root `llm_config.yaml` file."""
        config_path = Path("llm_config.yaml")
        if not config_path.exists():
            raise FileNotFoundError("llm_config.yaml not found in the project root.")
        with config_path.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f)
