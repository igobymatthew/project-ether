<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>project-ether (MVP)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <style>
    body { font-family: ui-sans-serif, system-ui; margin: 0; background: #0b0c10; color: #eee; }
    header { padding: 14px 16px; background: #11141a; border-bottom: 1px solid #222; }
    .wrap { padding: 16px; display: grid; gap: 12px; }
    .tiles { display: grid; grid-template-columns: repeat(2, minmax(220px, 1fr)); gap: 12px; }
    .tile { background: #141922; border: 1px solid #263042; border-radius: 16px; padding: 12px; min-height: 160px; position: relative; }
    .active { outline: 2px solid #6cf; }
    .name { position: absolute; bottom: 8px; left: 12px; padding: 4px 8px; background: rgba(0,0,0,.45); border-radius: 8px; font-size: 12px; }
    .controls { display: flex; gap: 8px; flex-wrap: wrap; }
    button, input[type="range"] { background: #1a2130; color: #e5f2ff; border: 1px solid #2b3a55; padding: 10px 14px; border-radius: 10px; }
    textarea { width: 100%; min-height: 70px; background: #0f131a; color: #def; border: 1px solid #2b3a55; border-radius: 8px; padding: 8px; }
    .log { font-family: ui-monospace, monospace; background: #0f131a; border: 1px solid #2b3a55; padding: 8px; border-radius: 8px; height: 160px; overflow: auto; }
  </style>
</head>
<body>
  <header><strong>Ether — MVP</strong></header>
  <div class="wrap">
    <div class="tiles">
      <div id="tile-mother" class="tile active"><div class="name">Mother</div></div>
      <div id="tile-brother" class="tile"><div class="name">Brother</div></div>
    </div>

    <div class="controls">
      <button id="dial">Dial</button>
      <button id="askBro">“Can I talk to my brother?”</button>
      <button id="end">End Call</button>
      <label>BG Energy <input id="bg" type="range" min="0" max="1" step="0.05" value="0.6"></label>
    </div>

    <textarea id="say" placeholder="Type what you say (e.g., “Hey Mom!”)"></textarea>
    <button id="send">Send</button>

    <div class="log" id="log"></div>
  </div>

<script>
  // ------------------ Microphone Streaming ------------------
  class MicrophoneStreamer {
    constructor(ws, onStop) {
      this.ws = ws;
      this.onStop = onStop;
      this.mediaStream = null;
      this.audioCtx = null;
      this.scriptProcessor = null;
      this.source = null;
      this.targetSampleRate = 16000; // Whisper needs 16kHz
    }

    async start() {
      try {
        this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        this.audioCtx = new (window.AudioContext || window.webkitAudioContext)();

        this.scriptProcessor = this.audioCtx.createScriptProcessor(4096, 1, 1);
        this.scriptProcessor.onaudioprocess = this._handleAudioProcess.bind(this);

        this.source = this.audioCtx.createMediaStreamSource(this.mediaStream);
        this.source.connect(this.scriptProcessor);
        this.scriptProcessor.connect(this.audioCtx.destination); // Connect to output to avoid garbage collection

        log("[mic] Microphone access granted, streaming started.");
      } catch (e) {
        log("[mic] Error getting microphone access: " + e);
        this.stop();
      }
    }

    stop() {
      if (this.mediaStream) {
        this.mediaStream.getTracks().forEach(track => track.stop());
      }
      if (this.scriptProcessor) {
        this.scriptProcessor.disconnect();
      }
      if (this.audioCtx) {
        this.audioCtx.close();
      }
      log("[mic] Microphone streaming stopped.");
      if (this.onStop) this.onStop();
    }

    _handleAudioProcess(event) {
      const inputData = event.inputBuffer.getChannelData(0);
      const resampledData = this._resample(inputData, this.audioCtx.sampleRate, this.targetSampleRate);
      const pcmData = this._floatTo16BitPCM(resampledData);
      if (this.ws && this.ws.readyState === WebSocket.OPEN) {
        this.ws.send(pcmData.buffer);
      }
    }

    _resample(data, from, to) {
        if (from === to) return data;
        const ratio = from / to;
        const newLength = Math.round(data.length / ratio);
        const result = new Float32Array(newLength);
        let offsetResult = 0;
        let offsetBuffer = 0;
        while (offsetResult < result.length) {
            const nextOffsetBuffer = Math.round((offsetResult + 1) * ratio);
            let accum = 0, count = 0;
            for (let i = offsetBuffer; i < nextOffsetBuffer && i < data.length; i++) {
                accum += data[i];
                count++;
            }
            result[offsetResult] = accum / count;
            offsetResult++;
            offsetBuffer = nextOffsetBuffer;
        }
        return result;
    }

    _floatTo16BitPCM(input) {
      const output = new Int16Array(input.length);
      for (let i = 0; i < input.length; i++) {
        const s = Math.max(-1, Math.min(1, input[i]));
        output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }
      return output;
    }
  }


  // ------------------ Audio Engine (WebAudio) ------------------
  class AudioEngine {
    constructor() {
      this.ctx = null;
      this.master = null;
      this.bgBus = null;
      this.bgGain = null;
      this.oneShotBus = null;
      this.bgLoops = [];
      this.bgDefaultDb = -6; // idle background target
      this.duckDb = -14;     // duck depth while speaking
      this.restoreT = 0.25;  // seconds
      this.duckT = 0.06;     // seconds
      this.assetsBase = "assets/sfx/"; // adjust if needed
      this._started = false;
    }

    async start() {
      if (this._started) return;
      this.ctx = new (window.AudioContext || window.webkitAudioContext)();
      this.master = this.ctx.createGain();
      this.master.gain.value = 1.0;
      this.master.connect(this.ctx.destination);

      this.bgBus = this.ctx.createGain();
      this.bgGain = this.bgBus.gain;
      this.bgGain.value = this.dbToGain(this.bgDefaultDb);
      this.bgBus.connect(this.master);

      this.oneShotBus = this.ctx.createGain();
      this.oneShotBus.gain.value = 1.0;
      this.oneShotBus.connect(this.master);

      // Preload and start loops
      await this._loadAndLoop("roomtone_livingroom.wav", 1.0);
      await this._loadAndLoop("walla_family_casual_1.wav", 0.8);

      this._started = true;
    }

    async _loadBuffer(url) {
      const res = await fetch(url);
      const arr = await res.arrayBuffer();
      return await this.ctx.decodeAudioData(arr);
    }

    async _loadAndLoop(file, gain=1.0) {
      const buf = await this._loadBuffer(this.assetsBase + file);
      const src = this.ctx.createBufferSource();
      src.buffer = buf;
      src.loop = true;
      const g = this.ctx.createGain();
      g.gain.value = gain;
      src.connect(g).connect(this.bgBus);
      src.start(0);
      this.bgLoops.push({src, g});
    }

    setBgEnergy(v) {
      // v: 0..1 from UI slider
      const targetDb = -24 + (v * 18); // maps 0=>-24dB .. 1=>-6dB
      this.bgDefaultDb = targetDb;
      this._rampBgTo(targetDb, 0.2);
    }

    duck() {
      // drop to duckDb quickly
      this._rampBgTo(this.duckDb, this.duckT);
    }

    unduck() {
      // restore to default smoothly
      this._rampBgTo(this.bgDefaultDb, this.restoreT);
    }

    _rampBgTo(db, t) {
      const now = this.ctx.currentTime;
      const val = this.dbToGain(db);
      this.bgGain.cancelScheduledValues(now);
      this.bgGain.setTargetAtTime(val, now, Math.max(0.01, t / 4)); // exp approach
    }

    dbToGain(db) { return Math.pow(10, db/20); }

    async playOneShot(file, db=-6) {
      const buf = await this._loadBuffer(this.assetsBase + file);
      const src = this.ctx.createBufferSource();
      src.buffer = buf;
      const g = this.ctx.createGain();
      g.gain.value = this.dbToGain(db);
      src.connect(g).connect(this.oneShotBus);
      src.start();
    }

    // Convenience for “near/far” asides
    // async playAside(proximity="near") {
    //   if (proximity === "far") {
    //     await this.playOneShot("aside_distant_chatter.wav", -14);
    //   } else {
    //     await this.playOneShot("aside_chair_scrape.wav", -10);
    //   }
    // }
    // Convenience for “near/far” asides with fallback
    async playAside(proximity="near") {
      const tryPlay = async (file, db) => {
        try { await this.playOneShot(file, db); return true; } catch (_) { return false; }
      };
      if (proximity === "far") {
        // try distant, fall back to chair scrape
        const ok = await tryPlay("aside_distant_chatter.wav", -14);
        if (!ok) await tryPlay("aside_chair_scrape.wav", -12);
      } else {
        // near default, fall back to distant if present
        const ok = await tryPlay("aside_chair_scrape.wav", -10);
        if (!ok) await tryPlay("aside_distant_chatter.wav", -12);
      }
    }

    playChunk(pcmData) {
        if (!this.ctx) return;
        const floatData = new Float32Array(pcmData.length);
        for (let i = 0; i < pcmData.length; i++) {
            floatData[i] = pcmData[i] / 32768.0;
        }

        const buffer = this.ctx.createBuffer(1, floatData.length, this.ctx.sampleRate);
        buffer.copyToChannel(floatData, 0);

        const source = this.ctx.createBufferSource();
        source.buffer = buffer;
        source.connect(this.master);
        source.start();
    }
  }

  // Singleton
  const AE = new AudioEngine();

  // ------------------ TTS with Ducking ------------------
  const synth = window.speechSynthesis;

  function playAudioWithDuck(url) {
    if (!url) return;
    const audio = new Audio(url);
    audio.oncanplaythrough = () => {
      AE.duck();
      audio.play();
    };
    audio.onended = () => AE.unduck();
    audio.onerror = () => AE.unduck();
  }

  function speakWithDuck(text) {
    if (!text) return;
    const ut = new SpeechSynthesisUtterance(text);
    ut.rate = 1.0;
    ut.onstart = () => AE.duck();
    ut.onend = () => AE.unduck();
    ut.onerror = () => AE.unduck();
    synth.cancel();
    synth.speak(ut);
  }

  // ------------------ UI + WS glue (Refactored for Audio Streaming) ------------------
  let ws, sceneTitle = "";
  const sayInput = document.getElementById("say");
  const sendButton = document.getElementById("send");
  const dialButton = document.getElementById("dial");

  // App state
  const AppState = {
    isCallActive: false,
    isTtsReady: false,
    isPushToTalk: false,
  };

  function renderUI() {
    // Renders UI based on AppState
    if (!AppState.isTtsReady) {
      dialButton.disabled = true;
      dialButton.textContent = "Loading...";
      sayInput.disabled = true;
      sendButton.disabled = true;
      sayInput.placeholder = "Loading expressive voices, please wait...";
    } else if (AppState.isCallActive) {
      dialButton.disabled = false;
      dialButton.textContent = AppState.isPushToTalk ? "Release to Send" : "Hold to Talk";
      sayInput.disabled = true;
      sendButton.disabled = true;
      sayInput.placeholder = "Audio call is active.";
    } else {
      dialButton.disabled = false;
      dialButton.textContent = "Dial (Audio)";
      sayInput.disabled = false;
      sendButton.disabled = false;
      sayInput.placeholder = "Type what you say (e.g., “Hey Mom!”)";
    }
  }

  document.addEventListener("DOMContentLoaded", () => {
    renderUI(); // Initial render
  });

  function log(s){
    const el = document.getElementById("log");
    el.textContent += s + "\n";
    el.scrollTop = el.scrollHeight;
  }

  function setActive(speaker){
    document.getElementById("tile-mother").classList.toggle("active", speaker==="mother");
    document.getElementById("tile-brother").classList.toggle("active", speaker==="brother");
  }

  async function handlePlan(plan){
    if(plan.controls?.end_call){ log("[system] call ended"); return; }
    const fg = plan.foreground || {};
    setActive(fg.speaker || "mother");

    // Start audio context on first meaningful event
    await AE.start();

    if (fg.line) {
      const isAudioURL = fg.line.endsWith(".wav");
      if (isAudioURL) {
        playAudioWithDuck(fg.line);
      } else {
        speakWithDuck(fg.line); // Fallback for text-only
      }
      log(fg.speaker + ": " + (fg.transcript || fg.line));
    }

    // Background asides -> play quick one-shots and log
    (plan.background || []).forEach(async (b) => {
      log("bg " + b.speaker + ": " + b.line);
      // small chance to toss an audible aside
      if (Math.random() < 0.6) { await AE.playAside(b.proximity || "near"); }
    });
  }

  // Wire up controls
  let micStreamer = null;

  dialButton.onmousedown = async () => {
    if (!AppState.isCallActive || AppState.isPushToTalk) return;
    AppState.isPushToTalk = true;
    renderUI();
    micStreamer = new MicrophoneStreamer(ws, () => {
      AppState.isPushToTalk = false;
      renderUI();
    });
    await micStreamer.start();
  };

  dialButton.onmouseup = () => {
    if (!AppState.isPushToTalk) return;
    if (micStreamer) micStreamer.stop();
  };

  dialButton.onclick = async () => {
    if (AppState.isCallActive) return; // PTT handled by mousedown/up

    // --- Start the audio call ---
    await AE.start();
    log("[system] Starting audio call...");

    ws = new WebSocket("ws://localhost:8000/ws-audio");
    ws.binaryType = "arraybuffer";

    ws.onopen = () => {
      log("[ws-audio] connected");
      AppState.isCallActive = true;
      renderUI();
    };

    ws.onmessage = (ev) => {
      const audioChunk = new Int16Array(ev.data);
      AE.playChunk(audioChunk);
    };

    ws.onclose = () => {
      log("[ws-audio] closed");
      AppState.isCallActive = false;
      AppState.isPushToTalk = false;
      if (micStreamer) micStreamer.stop();
      renderUI();
    };
  };

  function setUiReady(ready) {
    AppState.isTtsReady = ready;
    renderUI();
  }

  document.getElementById("send").onclick = () => {
    const text = document.getElementById("say").value.trim();
    if(!text || !ws) return;
    ws.send(JSON.stringify({type:"user_transcript", text}));
    log("you: " + text);
    document.getElementById("say").value = "";
  };

  document.getElementById("askBro").onclick = () => {
    if(!ws) return;
    ws.send(JSON.stringify({type:"user_transcript", text:"can I talk to my brother?"}));
    log('you: can I talk to my brother?');
  };

  document.getElementById("end").onclick = () => {
    if(ws){ ws.send(JSON.stringify({type:"end_call"})); ws.close(); }
  };

  document.getElementById("bg").oninput = (e) => {
    AE.setBgEnergy(parseFloat(e.target.value || "0.6"));
    if(ws){ ws.send(JSON.stringify({type:"set_bg_energy", value: e.target.value})); }
  };
</script>

</body>
</html>
